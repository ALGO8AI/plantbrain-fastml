{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63bab265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results (CV + Test):\n",
      "                   cv_rmse_mean  cv_rmse_std  cv_mae_mean  cv_mae_std  \\\n",
      "model                                                                   \n",
      "linear_regression      0.804085     0.130024     0.547236    0.003277   \n",
      "elastic_net            0.879462     0.008786     0.682731    0.005334   \n",
      "knn_regression         0.633650     0.010226     0.437635    0.004728   \n",
      "bayesian_ridge         0.804091     0.130040     0.547226    0.003273   \n",
      "decision_tree          0.714191     0.016612     0.452715    0.008101   \n",
      "lasso                  0.977362     0.010784     0.770404    0.007469   \n",
      "ridge                  0.804086     0.130027     0.547234    0.003276   \n",
      "adaboost               0.830984     0.078340     0.696649    0.084215   \n",
      "gradient_boosting      0.535417     0.013299     0.370083    0.005052   \n",
      "random_forest          0.514039     0.010519     0.332940    0.003713   \n",
      "svr                    0.767928     0.015141     0.540767    0.008894   \n",
      "\n",
      "                   cv_r2_mean  cv_r2_std  test_rmse  test_mae   test_r2  \n",
      "model                                                                    \n",
      "linear_regression    0.500343   0.181534   0.717256  0.529131  0.620670  \n",
      "elastic_net          0.419019   0.005075   0.871972  0.671467  0.439373  \n",
      "knn_regression       0.698314   0.009537   0.625272  0.433159  0.711726  \n",
      "bayesian_ridge       0.500333   0.181560   0.717252  0.529112  0.620674  \n",
      "decision_tree        0.616702   0.016109   0.686138  0.435018  0.652870  \n",
      "lasso                0.282509   0.002910   0.979344  0.764357  0.292804  \n",
      "ridge                0.500341   0.181539   0.717255  0.529127  0.620671  \n",
      "adaboost             0.478455   0.091410   0.762108  0.619810  0.571745  \n",
      "gradient_boosting    0.784548   0.010163   0.508634  0.353955  0.809244  \n",
      "random_forest        0.801458   0.007263   0.502257  0.326099  0.813997  \n",
      "svr                  0.556996   0.012839   0.735789  0.520067  0.600814  \n",
      "\n",
      "Best model by RMSE: random_forest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from plantbrain_fastml.managers.regressor_manager import RegressorManager\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import time\n",
    "# Load California housing dataset as DataFrame for compatibility\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize manager and add models (if not already added)\n",
    "manager = RegressorManager()\n",
    "# (If RegressorManager already adds models in __init__, no need to add explicitly)\n",
    "# Otherwise, you can add explicitly:\n",
    "# manager.add_model(\"linear_regression\", LinearRegressionRegressor())\n",
    "# manager.add_model(\"random_forest\", RandomForestRegressorWrapper())\n",
    "\n",
    "# Evaluate all models on training data with hypertuning and feature elimination\n",
    "time_start = time.time()\n",
    "results = manager.evaluate_all(\n",
    "    X_train, y_train,\n",
    "    hypertune=False,\n",
    "    hypertune_params={'n_trials': 2},\n",
    "    n_jobs=6,  # Set to -1 for all cores\n",
    "    cv_folds=5,\n",
    "    test_size=0.1,\n",
    "    feature_elimination=True,\n",
    "    fe_n_features=5,\n",
    "    fe_method='lasso',\n",
    "    return_plots=True  # set True if you want plots\n",
    ")\n",
    "\n",
    "print(\"Evaluation Results (CV + Test):\")\n",
    "print(results)\n",
    "\n",
    "# Get best model by metric (e.g., 'rmse')\n",
    "best_model_name, best_model = manager.get_best_model(metric='rmse', higher_is_better=False)\n",
    "print(f\"\\nBest model by RMSE: {best_model_name}\")\n",
    "time_end = time.time()\n",
    "\n",
    "# Evaluate best model on the test set separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3804f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for evaluation: 1.0 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken for evaluation: {(time_end - time_start)//60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92923970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_regression': {},\n",
       " 'random_forest': {},\n",
       " 'decision_tree': {},\n",
       " 'svr': {},\n",
       " 'knn_regression': {},\n",
       " 'gradient_boosting': {},\n",
       " 'elastic_net': {},\n",
       " 'bayesian_ridge': {},\n",
       " 'adaboost': {},\n",
       " 'lasso': {},\n",
       " 'ridge': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ccb775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b7343f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'scatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlinear_regression\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscatter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'scatter'"
     ]
    }
   ],
   "source": [
    "manager.get_plots()['linear_regression']['scatter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b099f9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_scores': {'rmse': (np.float64(0.8040853634139525),\n",
       "   np.float64(0.1300242365136351)),\n",
       "  'mae': (np.float64(0.5472359711631587), np.float64(0.003277065357366334)),\n",
       "  'r2': (np.float64(0.5003432933141967), np.float64(0.1815338559505305))},\n",
       " 'test_scores': {'rmse': np.float64(0.717256211776781),\n",
       "  'mae': 0.5291309251606496,\n",
       "  'r2': 0.6206697989665664},\n",
       " 'plots': {'line': <Figure size 640x480 with 1 Axes>,\n",
       "  'scatter': <Figure size 640x480 with 1 Axes>}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76a28ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Diabetes dataset...\n",
      "Dataset loaded successfully.\n",
      "Features shape: (442, 10)\n",
      "Target shape: (442,)\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training set size: 353\n",
      "Test set size: 89\n",
      "\n",
      "Initializing the RegressorManager...\n",
      "RegressorManager initialized.\n",
      "Available models: ['linear_regression', 'random_forest', 'decision_tree', 'svr', 'knn_regression', 'gradient_boosting', 'elastic_net', 'bayesian_ridge', 'adaboost', 'lasso', 'ridge']\n",
      "\n",
      "Starting model evaluation...\n",
      "\n",
      "Evaluation completed in 22.09 seconds.\n",
      "\n",
      "--- Evaluation Results (Cross-Validation & Test Scores) ---\n",
      "                   cv_rmse_mean  cv_rmse_std  cv_mae_mean  cv_mae_std  \\\n",
      "model                                                                   \n",
      "decision_tree         63.734719     4.122998    49.021606    2.958548   \n",
      "linear_regression     56.607819     0.976782    45.406853    0.920921   \n",
      "svr                   75.333713     1.347589    62.123351    0.917298   \n",
      "elastic_net           72.556032     1.578529    61.826766    0.605978   \n",
      "bayesian_ridge        56.599163     0.761051    45.420951    1.039664   \n",
      "lasso                 56.609383     0.913208    45.433837    0.963921   \n",
      "ridge                 56.592145     0.917346    45.399848    0.952108   \n",
      "gradient_boosting     60.094961     3.752841    49.051281    3.165353   \n",
      "random_forest         58.238358     3.234614    46.783200    3.160905   \n",
      "knn_regression        60.216962     2.697372    48.685187    2.491655   \n",
      "adaboost              59.319816     1.798207    47.944295    2.144901   \n",
      "\n",
      "                   cv_r2_mean  cv_r2_std  test_rmse   test_mae   test_r2  \n",
      "model                                                                     \n",
      "decision_tree        0.338936   0.072842  66.817221  52.249347  0.169585  \n",
      "linear_regression    0.478572   0.035343  54.532749  45.188425  0.446862  \n",
      "svr                  0.078157   0.033245  73.371725  60.374037 -0.001327  \n",
      "elastic_net          0.145557   0.003063  69.287041  57.821084  0.107059  \n",
      "bayesian_ridge       0.478950   0.031150  54.396745  45.069592  0.449618  \n",
      "lasso                0.478602   0.034226  54.487334  45.136296  0.447783  \n",
      "ridge                0.478920   0.034212  54.492036  45.150031  0.447688  \n",
      "gradient_boosting    0.413200   0.055258  57.680708  46.094068  0.381158  \n",
      "random_forest        0.449096   0.044596  58.086543  45.270926  0.372419  \n",
      "knn_regression       0.410859   0.041495  54.378772  45.962932  0.449981  \n",
      "adaboost             0.428621   0.023798  56.275288  45.203650  0.410947  \n",
      "\n",
      "--- Getting the Best Model ---\n",
      "Best performing model based on RMSE: 'knn_regression'\n",
      "\n",
      "Tuned Hyperparameters for knn_regression:\n",
      "{'n_neighbors': 15, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 67, 'p': 2}\n",
      "\n",
      "--- Making Predictions with the Best Model ---\n",
      "Applying feature elimination to the training set...\n",
      "Training the final 'knn_regression' model on the full training set...\n",
      "Applying the same feature elimination to the test set...\n",
      "\n",
      "Predictions made on the processed test set.\n",
      "     Actual   Predicted\n",
      "287   219.0  148.177198\n",
      "211    70.0  151.689799\n",
      "72    202.0  155.337577\n",
      "321   230.0  227.534412\n",
      "73    111.0  169.702104\n",
      "418    84.0  128.289367\n",
      "367   242.0  244.813694\n",
      "354   272.0  185.820641\n",
      "281    94.0   91.182490\n",
      "148    96.0  110.211916\n",
      "\n",
      "Notebook execution finished.\n"
     ]
    }
   ],
   "source": [
    "from plantbrain_fastml.managers.regressor_manager import RegressorManager\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# It's good practice to wrap the entire script logic in a main function\n",
    "def main():\n",
    "    # --- 1. Load and Prepare the Dataset ---\n",
    "    print(\"Loading the Diabetes dataset...\")\n",
    "    data = load_diabetes()\n",
    "    X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    y = pd.Series(data.target)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "    print(\"\\nSplitting data into training and testing sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "\n",
    "    # --- 2. Initialize the Regressor Manager ---\n",
    "    print(\"\\nInitializing the RegressorManager...\")\n",
    "    manager = RegressorManager()\n",
    "    print(\"RegressorManager initialized.\")\n",
    "    print(\"Available models:\", list(manager.models.keys()))\n",
    "\n",
    "\n",
    "    # --- 3. Evaluate All Models Using Default Metrics ---\n",
    "    print(\"\\nStarting model evaluation...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = manager.evaluate_all(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        hypertune=True,\n",
    "        hypertune_params={'n_trials': 2},\n",
    "        hypertune_metrics='r2',\n",
    "        n_jobs=-2,\n",
    "        cv_folds=3,\n",
    "        test_size=0.2,\n",
    "        feature_elimination=True,\n",
    "        fe_n_features=5,\n",
    "        fe_method='lasso',\n",
    "        return_plots=True\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nEvaluation completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "    # --- 4. Display Results and Get Best Model ---\n",
    "    print(\"\\n--- Evaluation Results (Cross-Validation & Test Scores) ---\")\n",
    "    print(results)\n",
    "\n",
    "    # Check if results are not empty before proceeding\n",
    "    if not results.empty:\n",
    "        print(\"\\n--- Getting the Best Model ---\")\n",
    "        best_model_name, best_model_object = manager.get_best_model(metric='rmse', higher_is_better=False)\n",
    "        print(f\"Best performing model based on RMSE: '{best_model_name}'\")\n",
    "\n",
    "        hyperparams = manager.get_hyperparameters()\n",
    "        print(f\"\\nTuned Hyperparameters for {best_model_name}:\")\n",
    "        print(hyperparams.get(best_model_name))\n",
    "\n",
    "\n",
    "        # --- 5. Make Predictions with the Best Model ---\n",
    "        print(\"\\n--- Making Predictions with the Best Model ---\")\n",
    "\n",
    "        # The preprocessor was already fitted during the evaluate_all call.\n",
    "        # First, process the TRAINING data.\n",
    "        print(\"Applying feature elimination to the training set...\")\n",
    "        X_train_processed = best_model_object.preprocessor.transform(X_train)\n",
    "\n",
    "        # **** THIS IS THE NEW, CRUCIAL STEP ****\n",
    "        # Now, train the best model on the processed training data.\n",
    "        print(f\"Training the final '{best_model_name}' model on the full training set...\")\n",
    "        best_model_object.train(X_train_processed, y_train) # Use the .train() method of your wrapper\n",
    "\n",
    "        # Now, process the TEST data using the same preprocessor\n",
    "        print(\"Applying the same feature elimination to the test set...\")\n",
    "        X_test_processed = best_model_object.preprocessor.transform(X_test)\n",
    "\n",
    "        # Finally, make predictions on the processed test data\n",
    "        predictions = best_model_object.predict(X_test_processed)\n",
    "\n",
    "        print(\"\\nPredictions made on the processed test set.\")\n",
    "        sample_comparison = pd.DataFrame({'Actual': y_test.values, 'Predicted': predictions}).head(10)\n",
    "        print(sample_comparison)\n",
    "        plots=manager.get_plots()\n",
    "\n",
    "        if plots and best_model_name in plots:\n",
    "            scatter_plot = plots[best_model_name].get('scatter')\n",
    "            if scatter_plot:\n",
    "                print(\"Displaying Predicted vs. Actual scatter plot...\")\n",
    "                # In a script you would use scatter_plot.show(), in a notebook this will display it\n",
    "                display(scatter_plot)\n",
    "        else:\n",
    "            print(f\"No plots found for model '{best_model_name}'.\")\n",
    "    else:\n",
    "        print(\"\\nEvaluation produced no results. Cannot determine the best model.\")\n",
    "\n",
    "    print(\"\\nNotebook execution finished.\")\n",
    "\n",
    "# This is the crucial part!\n",
    "# This tells Python to only run the main() function when the script is executed directly.\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b25413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "total_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f800c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Breast Cancer dataset...\n",
      "Dataset loaded successfully.\n",
      "Training set size: 455\n",
      "Test set size: 114\n",
      "\n",
      "RegressorManager initialized.\n",
      "Available models: ['random_forest', 'logistic_regression', 'svc']\n",
      "\n",
      "Starting model evaluation...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from plantbrain_fastml.managers.classifier_manager import ClassifierManager\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "print(\"Loading the Breast Cancer dataset...\")\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Split data, ensuring stratified split for classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "\n",
    "# --- 2. Initialize the Classifier Manager ---\n",
    "manager = ClassifierManager()\n",
    "print(\"\\nRegressorManager initialized.\")\n",
    "print(\"Available models:\", list(manager.models.keys()))\n",
    "\n",
    "\n",
    "# --- 3. Define Metrics and Evaluate All Models ---\n",
    "\n",
    "# Define the metrics to calculate as a DICTIONARY\n",
    "# Note: roc_auc requires probability scores, which our BaseClassifier handles.\n",
    "classification_metrics_to_calculate = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1': f1_score,\n",
    "    'roc_auc': roc_auc_score\n",
    "}\n",
    "\n",
    "print(\"\\nStarting model evaluation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate all models, using 'roc_auc' as the goal for hyperparameter tuning\n",
    "results = manager.evaluate_all(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    metrics=classification_metrics_to_calculate,\n",
    "    hypertune=True,\n",
    "    hypertune_params={'n_trials': 3}, # n_trials can be increased for a more thorough search\n",
    "    hypertune_metrics='roc_auc',\n",
    "    n_jobs=6, # Use all available CPU cores\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nEvaluation completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "# --- 4. Display Results and Get Best Model ---\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(results)\n",
    "\n",
    "print(\"\\n--- Getting the Best Model ---\")\n",
    "# Get the best model based on the test set's roc_auc score\n",
    "best_model_name, best_model_object = manager.get_best_model(metric='roc_auc', higher_is_better=True)\n",
    "print(f\"Best performing model based on Test ROC AUC: '{best_model_name}'\")\n",
    "\n",
    "\n",
    "# --- 5. In-depth Analysis of the Best Model ---\n",
    "print(f\"\\n--- Analysis of Best Model: {best_model_name} ---\")\n",
    "\n",
    "# Get the detailed classification report from the fitted model\n",
    "# Note: This requires a custom method on the BaseClassifier, which you've added.\n",
    "report = best_model_object.get_classification_report()\n",
    "if report:\n",
    "    print(\"Classification Report on Test Set:\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "\n",
    "# Get tuned hyperparameters from the manager\n",
    "hyperparams = manager.get_hyperparameters()\n",
    "print(f\"\\nTuned Hyperparameters for {best_model_name}:\")\n",
    "print(hyperparams.get(best_model_name))\n",
    "\n",
    "\n",
    "# --- 6. Make Predictions on New Data ---\n",
    "print(\"\\n--- Making Predictions on the Test Set ---\")\n",
    "# Use the best model's own preprocessor to transform the test data\n",
    "X_test_processed = best_model_object.preprocessor.transform(X_test)\n",
    "\n",
    "# Get final class predictions\n",
    "print(\"Applying feature elimination to the training set...\")\n",
    "X_train_processed = best_model_object.preprocessor.transform(X_train)\n",
    "\n",
    "# **** THIS IS THE NEW, CRUCIAL STEP ****\n",
    "# Now, train the best model on the processed training data.\n",
    "print(f\"Training the final '{best_model_name}' model on the full training set...\")\n",
    "best_model_object.train(X_train_processed, y_train) # Use the .train() method of your wrapper\n",
    "\n",
    "# Now, process the TEST data using the same preprocessor\n",
    "print(\"Applying the same feature elimination to the test set...\")\n",
    "X_test_processed = best_model_object.preprocessor.transform(X_test)\n",
    "\n",
    "# Finally, make predictions on the processed test data\n",
    "predictions = best_model_object.predict(X_test_processed)\n",
    "\n",
    "# Get prediction probabilities\n",
    "probabilities = best_model_object.predict_proba(X_test_processed)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(predictions[:5])\n",
    "print(\"\\nSample Probabilities (for class 0 and 1):\")\n",
    "print(probabilities[:5])\n",
    "\n",
    "print(\"\\nNotebook execution finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c2172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
